{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras \nimport numpy as np\n#from  utils.dataset import Dataset\nfrom re import template\nfrom numpy.lib.type_check import imag\nfrom tensorflow.keras import backend as  K \nfrom tensorflow import keras\nfrom tensorflow.keras import layers as L\nimport time\nimport pickle\nimport os\nfrom kaggle_datasets import KaggleDatasets\nfrom IPython.display import clear_output\nfrom tensorflow.keras import losses","metadata":{"id":"zUEK1KNlA28O","execution":{"iopub.status.busy":"2021-08-15T05:40:40.960289Z","iopub.execute_input":"2021-08-15T05:40:40.960709Z","iopub.status.idle":"2021-08-15T05:40:47.141575Z","shell.execute_reply.started":"2021-08-15T05:40:40.960676Z","shell.execute_reply":"2021-08-15T05:40:47.1403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n    \nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T05:40:47.143335Z","iopub.execute_input":"2021-08-15T05:40:47.143635Z","iopub.status.idle":"2021-08-15T05:40:53.042663Z","shell.execute_reply.started":"2021-08-15T05:40:47.143606Z","shell.execute_reply":"2021-08-15T05:40:53.04164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path() # you can list the bucket with \"!gsutil ls $GCS_DS_PATH\"\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2021-08-15T05:40:53.044698Z","iopub.execute_input":"2021-08-15T05:40:53.045116Z","iopub.status.idle":"2021-08-15T05:40:53.392552Z","shell.execute_reply.started":"2021-08-15T05:40:53.045073Z","shell.execute_reply":"2021-08-15T05:40:53.391229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NEW on TPU in TensorFlow 24: shorter cross-compatible TPU/GPU/multi-GPU/cluster-GPU detection code\n\ntry: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept ValueError: # detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-08-15T05:40:53.394494Z","iopub.execute_input":"2021-08-15T05:40:53.394913Z","iopub.status.idle":"2021-08-15T05:41:01.504775Z","shell.execute_reply.started":"2021-08-15T05:40:53.394864Z","shell.execute_reply":"2021-08-15T05:41:01.503373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_text_embeddings(path):\n    #Loading CNN-RNN text embeddings\n    with open(path, 'rb') as file:\n        embeds = pickle.load(file, encoding='latin1')\n    return embeds\n\ndef load_images(path):\n    #Loading images from pickle file\n    with open(path, 'rb') as f_in:\n        images = pickle.load(f_in)\n    return images\n\ndef load_data(embeddings_path, pickle_data_file):\n    #Load images and embeddings\n    embeddings = np.array(load_text_embeddings(embeddings_path))\n    x = np.array(load_images(pickle_data_file))        \n    return x, embeddings","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:07:32.776719Z","iopub.execute_input":"2021-07-29T18:07:32.777303Z","iopub.status.idle":"2021-07-29T18:07:32.789031Z","shell.execute_reply.started":"2021-07-29T18:07:32.777257Z","shell.execute_reply":"2021-07-29T18:07:32.787747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/gandata20/birds\"\ntrain_path = path + \"/train\"\ntest_path = path + \"/test\"\n\nembedding_train = train_path + \"/char-CNN-RNN-embeddings.pickle\"\nembedding_test = test_path + \"/char-CNN-RNN-embeddings.pickle\"\n\npickle_train_low = train_path + \"/64images.pickle\"\npickle_test_low = test_path + \"/64images.pickle\"\n\npickle_train_high = train_path + \"/256images.pickle\"\npickle_test_high = test_path + \"/256images.pickle\"","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:07:32.790846Z","iopub.execute_input":"2021-07-29T18:07:32.791415Z","iopub.status.idle":"2021-07-29T18:07:32.801264Z","shell.execute_reply.started":"2021-07-29T18:07:32.79134Z","shell.execute_reply":"2021-07-29T18:07:32.800061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Low resolution images\nx_train_low, train_embeds = load_data(embedding_train, pickle_train_low)\nx_test_low, test_embeds = load_data(embedding_test, pickle_test_low)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:07:32.803184Z","iopub.execute_input":"2021-07-29T18:07:32.803598Z","iopub.status.idle":"2021-07-29T18:07:52.52306Z","shell.execute_reply.started":"2021-07-29T18:07:32.803552Z","shell.execute_reply":"2021-07-29T18:07:52.521985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_low.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:07:52.524622Z","iopub.execute_input":"2021-07-29T18:07:52.525029Z","iopub.status.idle":"2021-07-29T18:07:52.539248Z","shell.execute_reply.started":"2021-07-29T18:07:52.524987Z","shell.execute_reply":"2021-07-29T18:07:52.537984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embedding =train_embeds[:,0]\ntrain_embedding.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:07:52.541089Z","iopub.execute_input":"2021-07-29T18:07:52.541897Z","iopub.status.idle":"2021-07-29T18:07:52.552518Z","shell.execute_reply.started":"2021-07-29T18:07:52.541836Z","shell.execute_reply":"2021-07-29T18:07:52.551017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_low = tf.cast(x_train_low,tf.float32)\ntrain_embedding = tf.cast(train_embedding,tf.float32)\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((x_train_low, train_embedding))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:07:52.557749Z","iopub.execute_input":"2021-07-29T18:07:52.558618Z","iopub.status.idle":"2021-07-29T18:07:53.34615Z","shell.execute_reply.started":"2021-07-29T18:07:52.558567Z","shell.execute_reply":"2021-07-29T18:07:53.345006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:07:53.34838Z","iopub.execute_input":"2021-07-29T18:07:53.348837Z","iopub.status.idle":"2021-07-29T18:07:53.358037Z","shell.execute_reply.started":"2021-07-29T18:07:53.348794Z","shell.execute_reply":"2021-07-29T18:07:53.356618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32 * 4\ntrain_ds= train_ds.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:07:53.360242Z","iopub.execute_input":"2021-07-29T18:07:53.360958Z","iopub.status.idle":"2021-07-29T18:07:53.369661Z","shell.execute_reply.started":"2021-07-29T18:07:53.360899Z","shell.execute_reply":"2021-07-29T18:07:53.368132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_ds = train_ds.prefetch(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:07:53.371904Z","iopub.execute_input":"2021-07-29T18:07:53.372696Z","iopub.status.idle":"2021-07-29T18:07:53.380389Z","shell.execute_reply.started":"2021-07-29T18:07:53.372636Z","shell.execute_reply":"2021-07-29T18:07:53.378952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef show_image(x):\n    img = plt.figure()\n    ax = img.add_subplot(1,1,1)\n    ax.imshow(x) ","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:07:53.382474Z","iopub.execute_input":"2021-07-29T18:07:53.383014Z","iopub.status.idle":"2021-07-29T18:07:53.392337Z","shell.execute_reply.started":"2021-07-29T18:07:53.382943Z","shell.execute_reply":"2021-07-29T18:07:53.390911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset = Dataset(image_size=(64,64),data_base_path=\"./data\",batch_size=128)\n# train_ds = dataset.get_train_ds()","metadata":{"id":"6ryJLiouwzvX","execution":{"iopub.status.busy":"2021-07-29T18:07:53.394081Z","iopub.execute_input":"2021-07-29T18:07:53.394672Z","iopub.status.idle":"2021-07-29T18:07:53.402948Z","shell.execute_reply.started":"2021-07-29T18:07:53.394597Z","shell.execute_reply":"2021-07-29T18:07:53.401556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n############################################################\n# Conditioning Augmentation Network\n############################################################\nclass ConditioningAugmentation(keras.Model):\n    def __init__(self, *args, **kwargs):\n        super(ConditioningAugmentation, self).__init__(*args, **kwargs)\n        self.dense = L.Dense(256)\n        self.activation = L.LeakyReLU(alpha=0.2)\n        \n\n    def call(self,input):\n        x  = self.dense(input)\n        phi= self.activation(x)\n        mean = phi[:,:128]\n        std =tf.math.exp(phi[:,128:])\n        epsilon = K.random_normal(shape = K.constant((mean.shape[1], ), dtype = 'int32'))\n        output = mean + std*epsilon\n        return output,phi\n\nclass EmbeddingCompresssor(keras.Model):\n    def __init__(self):\n        super(EmbeddingCompresssor, self).__init__()\n        self.dense = L.Dense(128)\n\n    def call(self,input):\n        x = self.dense(input)\n        x = L.LeakyReLU(0.2)(x)\n        return x\n\n\n############################################################\n# Stage 1 Generator Network (CGAN)\n############################################################\n\n\ndef UpSamplingBlock(input,num_filters):\n    x = L.UpSampling2D(size=2)(input)\n    x = L.Conv2D(num_filters,kernel_size=3,padding='same',strides=1,use_bias=False)(x)\n    x = L.BatchNormalization()(x)\n    x = L.ReLU()(x)\n    return x\n\n\nclass Stage1Generator(keras.Model):\n    def __init__(self):\n        super(Stage1Generator, self).__init__(name='stage_1_generator')\n        self.augmentation = ConditioningAugmentation()\n        self.concat = L.Concatenate(axis=1)\n        self.dense = tf.keras.layers.Dense(units = 128*8*4*4, kernel_initializer = tf.random_normal_initializer(stddev = 0.02))\n        self.reshape = tf.keras.layers.Reshape(target_shape = (4, 4, 128*8), input_shape = (128*8*4*4, ))\n        self.batchnorm1 = tf.keras.layers.BatchNormalization(axis = -1, momentum = 0.99)\n        self.activation = L.ReLU()\n\n    def call(self,inputs):\n        embedding , noise = inputs\n        c , phi = self.augmentation(embedding)\n        gen_input = self.concat([c,noise])\n        x = self.dense(gen_input)\n        x = self.reshape(x)\n        x = self.batchnorm1(x)\n        x = self.activation(x)\n        x = UpSamplingBlock(x, 512)\n        x = UpSamplingBlock(x, 256)\n        x = UpSamplingBlock(x,128)\n        x = UpSamplingBlock(x,3)\n        x = L.Conv2D(3,kernel_size=3,padding='same')(x)\n        x = L.Activation('tanh')(x)\n\n        return x,phi\n\nclass Stage1Discriminator(keras.Model):\n    def __init__(self,*args, **kwargs):\n        super(Stage1Discriminator, self).__init__(*args,**kwargs)\n        self.l1 = L.Conv2D(64,kernel_size=4,strides=2,padding='same',kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev = 0.02 ))\n        self.l2 = L.Conv2D(128,kernel_size=4,strides=2,padding='same',kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev =0.02))\n        self.l3 = L.BatchNormalization(axis = -1)\n        self.l4 = L.Conv2D(256,kernel_size=4,strides=2,padding='same',kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev = 0.02))\n        self.l5 = L.BatchNormalization(axis = -1)\n        self.l6 = L.Conv2D(516,kernel_size=4,strides=2,padding='same',kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev = 0.02))\n        self.l7 = L.BatchNormalization(axis = -1)\n        self.embedding = EmbeddingCompresssor()\n        self.l9 = L.Reshape(target_shape = (1,1,128))\n        self.concat= L.Concatenate() \n        self.l11= L.Conv2D(filters = 1024, kernel_size=4,strides=2,padding='same',kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev = 0.02))\n        self.l12= L.BatchNormalization(axis = -1)\n        self.l13= L.Conv2D(filters = 1\n                            ,kernel_size=4,strides=2,padding='same',kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev = 0.02))\n        \n\n    def call(self,inputs):\n        I , E = inputs #\n        x  = self.l1(I)\n        x  = self.l2(x)\n        x  = self.l3(x)\n        x  = self.l4(x)\n        x  = self.l5(x)\n        x  = self.l6(x)\n        x  = self.l7(x)\n\n        t  = self.embedding(E)\n        t  = self.l9(t)\n        t  = tf.tile(t,(1,4,4,1))\n\n        merged_input  = self.concat([t,x])\n\n        y = self.l11(merged_input)\n        y =self.l12(y)\n        y =L.LeakyReLU()(y)\n\n        y = self.l13(y)\n        y = L.Activation('sigmoid')(y)\n        y = tf.squeeze(y)\n        return y\n\n\ndef KL_loss(y_true, y_pred):\n    kl = tf.keras.losses.KLDivergence()\n    loss =kl(y_true, y_pred)\n    loss = tf.reduce_mean(loss)\n    \n    return loss\n\ndef loss(true_label,predicted_label):\n    #print(f\"true_label :{true_label} predicted_label {predicted_label}\")\n    #loss=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(true_label, predicted_label))\n    loss=KL_loss(true_label,predicted_label)\n    return loss\n    \ndef predict(x,true):\n    if true == 0 and x <0.5:\n        return 1\n    if true == 1 and x>0.5:\n        return 1\n    return 0\n        \ndef accuracy(y_true, y_pred):\n    acc =0\n    if y_true[0]> 0.5:\n        acc = tf.reduce_mean(tf.map_fn(fn = lambda x : predict(x,1) ,elems=y_pred))\n    else :\n        acc = tf.reduce_mean(tf.map_fn(fn = lambda x : predict(x,0) ,elems=y_pred))\n    return acc\n\nclass Stage1Model(tf.keras.Model):\n  def __init__(self,lr_g=0.0001,lr_d=0.0001):\n    super(Stage1Model, self).__init__()\n    self.generator = Stage1Generator()\n    self.discriminator = Stage1Discriminator()\n    self.generator_optimizer = keras.optimizers.Adam(learning_rate= lr_g, beta_1= 0.5 , beta_2= 0.999)\n    self.discriminator_optimizer = keras.optimizers.Adam(learning_rate= lr_d, beta_1= 0.5 , beta_2= 0.999)\n    self.noise_dim = 100\n    self.c_dim = 128\n    self.loss = {}\n\n\n  def load_weights(self,path):\n    z_noise = tf.random.normal((1, self.noise_dim))\n    embedding = tf.random.normal((1,1024))\n    image, phi = self.generator([embedding, z_noise])\n    logit = self.discriminator([image,embedding])\n    self.generator.load_weights(path+\"/stage1_generator.h5\")\n    self.discriminator.load_weights(path+\"/stage1_discriminator.h5\")\n\n  def train(self, train_ds, batch_size = 64, num_epochs = 600,save_weights_epoch=5,train_length=8855):\n    for epoch in range(num_epochs):\n      print(\"Epoch %d/%d:\\n \"%(epoch + 1, num_epochs), end = \"\")\n      start_time = time.time()\n      if epoch % 100 == 0:\n        K.set_value( self.generator_optimizer.learning_rate,  self.generator_optimizer.learning_rate / 2)\n        K.set_value( self.generator_optimizer.learning_rate,  self.generator_optimizer.learning_rate / 2)\n    \n      generator_loss_log = []\n      discriminator_loss_log = []\n      steps_per_epoch = train_length//batch_size\n      batch_iter = iter(train_ds)\n      d_acc =0\n      g_acc =0\n      \n      for i in range(steps_per_epoch):\n        if i % 5 == 0:\n          print(\"=\", end = \"\")\n        image_batch, embedding_batch = next(batch_iter)\n        batch_size = image_batch.shape[0]\n        z_noise = tf.random.normal((batch_size, self.noise_dim))\n\n        mismatched_images = tf.roll(image_batch, shift = 1, axis = 0)\n\n        real_labels = tf.random.uniform(shape = (batch_size, ), minval = 0.9, maxval = 1.0)\n        fake_labels = tf.random.uniform(shape = (batch_size, ), minval = 0.0, maxval = 0.1)\n        mismatched_labels = tf.random.uniform(shape = (batch_size, ), minval = 0.0, maxval = 0.1)\n        \n        \n        with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n          fake_images,phi = self.generator([embedding_batch, z_noise])\n          real_logits = self.discriminator([image_batch, embedding_batch])\n          fake_logits = self.discriminator([fake_images, embedding_batch])\n          mismatched_logits = self.discriminator([mismatched_images, embedding_batch])\n\n          l_sup = loss(real_labels, fake_logits)\n          l_klreg = KL_loss(tf.random.normal((phi.shape[0], phi.shape[1])), phi)\n          generator_loss = l_sup #+ 2.0*l_klreg\n          g_acc =g_acc+accuracy(real_labels, fake_logits)/batch_size\n            \n          l_real = loss(real_labels, real_logits)\n          l_fake = loss(fake_labels, fake_logits)\n          l_mismatched = loss(mismatched_labels, mismatched_logits)\n          discriminator_loss = 0.5*tf.add(l_real, 0.5*tf.add(l_fake, l_mismatched))\n            \n          d_acc = d_acc+ (accuracy(real_labels, real_logits)+accuracy(fake_labels, fake_logits) +accuracy(mismatched_labels, mismatched_logits))/(3*batch_size)\n       \n        generator_gradients = generator_tape.gradient(generator_loss, self.generator.trainable_variables)\n        discriminator_gradients = discriminator_tape.gradient(discriminator_loss, self.discriminator.trainable_variables)\n        \n        self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.trainable_variables))\n        self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.trainable_variables))\n        \n        generator_loss_log.append(generator_loss)\n        discriminator_loss_log.append(discriminator_loss)\n        #break\n\n      end_time = time.time()\n\n      if epoch % 1 == 0:\n        epoch_time = end_time - start_time\n        template = \" - generator_loss: {:.4f}- generator accuracy: {:.4f} - discriminator_loss: {:.4f} - discriminator accuracy: {:.4f} - epoch_time: {:.2f} \"\n        print(template.format(tf.reduce_mean(generator_loss_log),g_acc, tf.reduce_mean(discriminator_loss_log), d_acc,epoch_time))\n\n      if (epoch + 1) % save_weights_epoch == 0 or epoch == num_epochs - 1:\n        save_path = \"./lr_results/epoch_\" + str(epoch + 1)\n        temp_embeddings = None\n        for _, embeddings in train_ds:\n          temp_embeddings = embeddings.numpy()\n          break\n        if os.path.exists(save_path) == False:\n          os.makedirs(save_path)\n        temp_batch_size = 10\n        temp_z_noise = tf.random.normal((temp_batch_size, self.noise_dim))\n        temp_embedding_batch = temp_embeddings[0:temp_batch_size]\n        fake_images, _ = self.generator([temp_embedding_batch, temp_z_noise])\n        for i, image in enumerate(fake_images):\n          image = 127.5*image + 127.5\n          image = image.numpy().astype('uint8')\n          image  = keras.preprocessing.image.array_to_img(image)\n          image.save(save_path + \"/gen_%d.png\"%(i))\n\n        weights_path = f\"./weights/weights_{epoch+1}\"\n\n        if os.path.exists(weights_path)== False:\n          os.makedirs(weights_path)\n        self.generator.save_weights(weights_path+\"/stage1_generator.h5\")\n        self.discriminator.save_weights(weights_path+\"/stage1_discriminator.h5\")\n        clear_output(wait=True)\n\n    \ndef generate_image(self, embedding, batch_size= 64):\n        z_noise = tf.random.normal((batch_size, self.noise_dim))\n        generated_image = self.generator([embedding, z_noise])\n        return generated_image                \n","metadata":{"id":"sO375URWPcZC","execution":{"iopub.status.busy":"2021-07-29T18:11:16.194486Z","iopub.execute_input":"2021-07-29T18:11:16.194923Z","iopub.status.idle":"2021-07-29T18:11:16.258405Z","shell.execute_reply.started":"2021-07-29T18:11:16.194893Z","shell.execute_reply":"2021-07-29T18:11:16.257306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Stage1Model(lr_g=0.0001,lr_d=0.0001)\n#model.load_weights(path=\"./weights/weights_20\")\nmodel.train(train_ds,batch_size=256,num_epochs=1,save_weights_epoch=20)","metadata":{"id":"r6R9D3W-JO5m","execution":{"iopub.status.busy":"2021-07-29T18:11:17.108287Z","iopub.execute_input":"2021-07-29T18:11:17.108752Z","iopub.status.idle":"2021-07-29T18:11:59.983234Z","shell.execute_reply.started":"2021-07-29T18:11:17.108721Z","shell.execute_reply":"2021-07-29T18:11:59.981812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train(train_ds,batch_size=256,num_epochs=10,save_weights_epoch=20)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T18:21:53.180138Z","iopub.execute_input":"2021-07-29T18:21:53.18054Z","iopub.status.idle":"2021-07-29T18:35:05.838773Z","shell.execute_reply.started":"2021-07-29T18:21:53.180508Z","shell.execute_reply":"2021-07-29T18:35:05.837781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i=model.generate_image(train_embedding[0],batch_size=1)\nshow_image(i[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-29T06:43:34.464503Z","iopub.execute_input":"2021-07-29T06:43:34.464875Z","iopub.status.idle":"2021-07-29T06:43:34.751797Z","shell.execute_reply.started":"2021-07-29T06:43:34.464834Z","shell.execute_reply":"2021-07-29T06:43:34.750277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.generator.summary()","metadata":{"id":"XE5CGdWAO1oc","outputId":"a0e7c519-df68-4a29-ae9b-341f605fa2b3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndataset = Dataset(image_size=(256,256),data_base_path=\"./data\",batch_size=1)\ntrain_ds = dataset.get_test_ds()","metadata":{"id":"pI9uhvhlWFoZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset.test_filenames)","metadata":{"id":"neAbJUlJNiV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ResidualBlock(input, num_filters):\n    x  =  L.Conv2D(filters = num_filters, kernel_size= 3 , strides=1, padding='same')(input)\n    x  =  L.BatchNormalization()(x)\n    x  =  L.ReLU()(x)\n    x  =  L.Conv2D(filters = num_filters, kernel_size=3, strides=1, padding='same')(x)\n    x  =  L.BatchNormalization()(x)\n    x  =  L.ReLU()(x)\n    return x\n\n\nclass Stage2Generator(keras.Model):\n    def __init__(self,*args, **kwargs):\n        super(Stage2Generator, self).__init__(*args, **kwargs)\n\n    def call(self,inputs):\n        x = ResidualBlock(inputs, 128)\n        x = ResidualBlock(x,256)\n        x = UpSamplingBlock(x,256)\n        x = ResidualBlock(x,128)\n        x = UpSamplingBlock(x,256)\n        x = ResidualBlock(x,3)\n        return x\n\ndef DownSamplingBlock(  inputs,\n                        num_filters, \n                        kernel_size= 4,\n                        strides = 2,\n                        batch_norm=True,\n                        activation= True):\n    x = L.Conv2D(filters = num_filters, kernel_size= kernel_size , strides=strides, padding='same')(inputs)\n    if batch_norm:\n        x = L.BatchNormalization()(x)\n    if activation:\n        x = L.LeakyReLU()(x)\n    #print(f\" x shape {x.shape}\")\n    return x\n\n\nclass Stage2Discriminator(tf.keras.Model):\n  def __init__(self):\n    super(Stage2Discriminator, self).__init__()\n    self.embed = EmbeddingCompresssor()\n    self.reshape = tf.keras.layers.Reshape(target_shape = (1, 1, 128))\n    self.conv_out = tf.keras.layers.Conv2D(filters = 1, kernel_size = 4, strides = 1, padding = \"valid\", kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev = 0.02))\n\n  def call(self, inputs):\n    I, E = inputs\n    T = self.embed(E)\n    T = self.reshape(T)\n    T = tf.tile(T, (1, 4, 4, 1))\n    \n    x = DownSamplingBlock(I,num_filters=64,batch_norm=False)\n    x = DownSamplingBlock(x,num_filters=128)\n    x = DownSamplingBlock(x, num_filters=256)\n    x = DownSamplingBlock(x,num_filters=512)\n    x = DownSamplingBlock(x,num_filters=1024)\n    x = DownSamplingBlock(x,num_filters=512)\n    x = DownSamplingBlock(x,num_filters=128,kernel_size=1,strides=1)\n    \n    y = DownSamplingBlock(x, num_filters=128,kernel_size=1,strides=1)\n    y = DownSamplingBlock(y, num_filters=256,kernel_size=3,strides=1)\n    y = DownSamplingBlock(y, num_filters=128,kernel_size=3,strides=1)\n\n    A = tf.keras.layers.Add()([x,y])\n    A = tf.nn.leaky_relu(A)\n    merged_input = tf.keras.layers.concatenate([A, T])\n    \n    z = DownSamplingBlock(merged_input,128,kernel_size=1,strides=1)\n    z = self.conv_out(z)\n    print(f\" z {z.shape}\")\n    z = \n    print(f\" z {z.shape} and z :{z}\")\n\n    return z\n\n\nclass Stage2Model(keras.Model):\n    def __init__(self):\n        super(Stage2Model, self).__init__()\n        self.generator1 = Stage1Generator()\n        self.generator2 = Stage2Generator()\n        self.discriminator2 = Stage2Discriminator()\n        self.generator2_optimizer = keras.optimizers.Adam(learning_rate= 0.0001, beta_1= 0.5 , beta_2= 0.999)\n        self.discriminator2_optimizer = keras.optimizers.Adam(learning_rate= 0.0001, beta_1= 0.5 , beta_2= 0.999)\n        self.noise_dim = 100\n    def train(self, train_ds, batch_size= 64, num_epochs =1,steps_per_epoch =125):\n\n        for epoch in range(num_epochs):\n            print(\"Epoch %d/%d:\\n  \"%(epoch + 1, num_epochs), end = \"\")\n            start_time = time.time()\n            if epoch % 100 == 0:\n                K.set_value(self.generator2_optimizer.learning_rate, self.generator2_optimizer.learning_rate / 2)\n                K.set_value(self.discriminator2_optimizer.learning_rate, self.discriminator2_optimizer.learning_rate / 2)\n            \n            generator_loss_log = []\n            discriminator_loss_log = []\n            steps_per_epoch = steps_per_epoch\n            batch_iter = iter(train_ds) \n            for i in range(steps_per_epoch):\n                if i% 5 ==0:\n                    print(\"=\", end = \"\")\n\n                hr_image_batch,embedding_batch = next(batch_iter)\n                batch_size = hr_image_batch.shape[0]\n                z_noise = tf.random.normal((batch_size, self.noise_dim))\n                mismatched_images = tf.roll(hr_image_batch, shift=1, axis = 0)\n\n                real_labels = tf.random.uniform(shape = (batch_size, ), minval = 0.9, maxval=1.0)\n                fake_labels = tf.random.uniform(shape = (batch_size, ), minval = 0.0 , maxval = 0.1)\n                mismatched_labels = tf.random.uniform(shape = (batch_size, ), minval = 0.0, maxval = 0.1)\n\n                with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape:\n                    lr_fake_images , phi = self.generator1([embedding_batch,z_noise])\n                    hr_fake_images        = self.generator2(lr_fake_images)\n                    real_logits = self.discriminator2([hr_image_batch, embedding_batch])\n                    fake_logits = self.discriminator2([hr_fake_images, embedding_batch])\n                    mismatched_logits = self.discriminator2([mismatched_images, embedding_batch])\n\n                    l_sup = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(real_labels,real_logits))\n                    l_klreg = KL_loss(tf.random.normal((phi.shape[0], phi.shape[1])), phi)\n                    generator_loss = l_sup + 2.0*l_klreg\n                    \n                    \n                    l_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(real_labels,real_logits))\n                    l_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(fake_logits,fake_labels))\n                    l_mismatched = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(mismatched_logits,mismatched_labels))\n                    discriminator_loss = 0.5*tf.add(l_real,tf.add(l_fake, l_mismatched))\n\n                generator_gradients = generator_tape.gradient(generator_loss,self.generator2.trainable_variables)\n                self.generator2_optimizer.apply_gradients(zip(generator_gradients, self.generator2.trainable_variables))             \n\n                discriminator_gradients = discriminator_tape.gradient(discriminator_loss,self.discriminator2.trainable_variables)\n                self.discriminator2_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator2.trainable_variables))\n\n                generator_loss_log.append(generator_loss)\n                discriminator_loss_log.append(discriminator_loss)\n\n                end_time = time.time()\n\n                if epoch % 1 == 0:\n                    epoch_time = end_time - start_time\n                    template = \" - generator_loss: {:.4f} - discriminator_loss: {:.4f} - epoch_time: {:.2f} s\"\n                    print(template.format(tf.reduce_mean(generator_loss_log), tf.reduce_mean(discriminator_loss_log), epoch_time))\n\n                if (epoch + 1) % 10 == 0 or epoch == num_epochs - 1:\n                    save_path = \"./hr_results/epoch_\" + str(epoch + 1)\n                    temp_embeddings = None\n                    for _, embeddings in train_ds:\n                        temp_embeddings = embeddings.numpy()\n                        break\n                    if os.path.exists(save_path) == False:\n                        os.makedirs(save_path)\n                    temp_batch_size = 10\n                    temp_z_noise = tf.random.normal((temp_batch_size, self.noise_dim))\n                    temp_embedding_batch = temp_embeddings[0:temp_batch_size]\n                    fake_images, _ = self.generator2([temp_embedding_batch, temp_z_noise])\n                    for i, image in enumerate(fake_images):\n                            image = 127.5*image + 127.5\n                            image = image.numpy().astype('uint8')\n                            image  = keras.preprocessing.image.array_to_img(image)\n                            image.save(save_path + \"/gen_%d.png\"%(i))\n\n                    weights_path = f\"./weights/hr_weights_{epoch+1}\"\n                    if os.path.exists(weights_path)== False:\n                        os.mkdirs(weights_path)\n                    self.generator2.save_weights(weights_path+\"/stage2_generator.h5\")\n                    self.discriminator2.save_weights(weights_path+\"/stage2_discriminator.h5\")\n\n\nmodel2= Stage2Model()\n\n","metadata":{"id":"0I3i7kPFKM8I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.train(train_ds,batch_size=4)","metadata":{"id":"vMKBd1CxWsuc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  ","metadata":{"id":"8WEh-oXVOqiJ"},"execution_count":null,"outputs":[]}]}